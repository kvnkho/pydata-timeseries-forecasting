{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with Fugue\n",
    "\n",
    "In the first section, we saw how to scale `StatsForecast` on top of Spark, Dask, and Ray just by changing one line of code. When dealing with large data, we'll need to preprocess it also to get it in the same format. How do we prototype on small data, and scale it seamlessly? [Fugue](https://github.com/fugue-project/fugue/) allows us to scale existing Python and Pandas code to Spark, Dask, or Ray just by changing the engine as well.\n",
    "\n",
    "In this section, we'll preprocess the data shown in the previous section using Dask to speed it up. One of the advantages of Fugue is being able to decouple logic and execution. Code can be prototyped on the local system, and brought to the full scale when ready.\n",
    "\n",
    "Below is an image of the architecture of Fugue. It's an abstraction layer on top of the distributed computing frameworks.\n",
    "\n",
    "![architecture](../img/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Data\n",
    "\n",
    "We'll start with pre-processing the `training_data` that contains the sales volume. The problem with this file is that it is very wide with around 2000 columns, but `StatsForecast` expects data in a long format where each data point is one row. Though this is a memory efficient way to store the data, it's unfriendly to work with for machine learning. We need to transform the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "download_path = os.path.abspath(os.path.join(\".\",\"..\",\"data\",\"m5-forecasting-accuracy.zip\"))\n",
    "unzipped_path = os.path.abspath(os.path.join(\".\",\"..\",\"data\",\"m5-forecasting-accuracy-unzipped\"))\n",
    "\n",
    "# Read in the data\n",
    "INPUT_DIR = unzipped_path\n",
    "WORKING_DIR = os.path.join(unzipped_path, \"..\", \"working\")\n",
    "training_data = pd.read_csv(f'{INPUT_DIR}/sales_train_evaluation.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the first row of the DataFrame. We have the days as column names and and the time series for one `id` is contained in the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0       0       3       3       0       1  \n",
       "\n",
       "[1 rows x 1947 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.iloc[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the `calendar` data to align to the `training_data`. We'll display the head also just to remember what the data format looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  wm_yr_wk   weekday  wday  month  year    d event_name_1  \\\n",
       "0 2011-01-29     11101  Saturday     1      1  2011  d_1          NaN   \n",
       "1 2011-01-30     11101    Sunday     2      1  2011  d_2          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN          NaN        0        0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\n",
    "calendar[\"date\"] = pd.to_datetime(calendar[\"date\"])\n",
    "calendar.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to pivot the timeseries information into a long format. Note that this function does not use Pandas. It runs on each row of data in the `training_data` DataFrame and creates a new day entry. While this logic can be done in Pandas, one of the advantages of using Fugue is not everything has to be expressed in Pandas. Some opeartions will be clearer in native Python. Fugue will apply the conversions to run this on top of Pandas, Spark, Dask, or Ray.\n",
    "\n",
    "In the `format_sales` function, we treat each function as a row and loop through the rows of the DataFrame. For each row, we pull out each day and value, and then `yield` a new row. Adding `0.01` to the timeseries values is a technique to improve numerical stability when dealing with timeseries data. If this function is not clear, the results below will make it clearer when we apply it on the first row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Any, Dict\n",
    "from datetime import timedelta\n",
    "\n",
    "start = calendar['date'].min()\n",
    "\n",
    "def format_sales(df:Iterable[List[Any]], start) -> Iterable[List[Any]]:\n",
    "    for row in df:\n",
    "        counter = 0\n",
    "        for y in row[6:]:\n",
    "            # help with convergence\n",
    "            if y == 0:\n",
    "                y = y + 0.01\n",
    "            date = start + timedelta(counter)\n",
    "            yield row[:6] + [date, y]\n",
    "            counter=counter+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Fugue to run it on the first row of data from our `training_data` DataFrame. The `transform()` function of Fugue is used to distribute one step of Python or Pandas. As long as the implementation on Pandas works, it will also work on Spark, Dask, and Ray.\n",
    "\n",
    "Schema is a requirement for the distributed backends, so it's also required when applying function on top of Pandas. It's also needed to apply column names to the `List` output. The Fugue schema expression will be more minimal compared to defining it directly on the backend.\n",
    "\n",
    "We don't necessarily need all of the hierarchichal information, but they will be useful in the next section when we apply hierarchichal forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1941 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          unique_id        item_id    dept_id   cat_id  \\\n",
       "0     HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1     HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "2     HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "3     HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "4     HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "...                             ...            ...        ...      ...   \n",
       "1936  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1937  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1938  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1939  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1940  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "\n",
       "     store_id state_id         ds     y  \n",
       "0        CA_1       CA 2011-01-29  0.01  \n",
       "1        CA_1       CA 2011-01-30  0.01  \n",
       "2        CA_1       CA 2011-01-31  0.01  \n",
       "3        CA_1       CA 2011-02-01  0.01  \n",
       "4        CA_1       CA 2011-02-02  0.01  \n",
       "...       ...      ...        ...   ...  \n",
       "1936     CA_1       CA 2016-05-18  0.01  \n",
       "1937     CA_1       CA 2016-05-19  3.00  \n",
       "1938     CA_1       CA 2016-05-20  3.00  \n",
       "1939     CA_1       CA 2016-05-21  0.01  \n",
       "1940     CA_1       CA 2016-05-22  1.00  \n",
       "\n",
       "[1941 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fugue import transform\n",
    "\n",
    "transform(training_data.iloc[0:1], \n",
    "          format_sales, \n",
    "          schema=\"unique_id:str,item_id:str,dept_id:str,cat_id:str,store_id:str,state_id:str,ds:date,y:float\",\n",
    "          params={\"start\": start})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When run on the first row, it expanded the data out to one row per day. Because it worked when we tested it quickly, we can now run it on top of Spark, Dask, or Ray by changing the engine. In the example below, we run it on top of Dask. We can demo this on the first 100 rows of data.\n",
    "\n",
    "As mentioned in the first notebook, we need to call `.compute()` in order to trigger the execution of the Dask DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pydata/lib/python3.8/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 49193 instead\n",
      "  warnings.warn(\n",
      "2023-02-13 00:35:33,561 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-j1o9lf_1', purging\n",
      "2023-02-13 00:35:33,562 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-jg_tza5a', purging\n",
      "2023-02-13 00:35:33,564 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-1qr0fzd8', purging\n",
      "2023-02-13 00:35:33,565 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-69row5ay', purging\n",
      "2023-02-13 00:35:33,565 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-8xxa3ryl', purging\n",
      "2023-02-13 00:35:33,566 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-krxhuc_5', purging\n",
      "2023-02-13 00:35:33,567 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-abd52p8x', purging\n",
      "2023-02-13 00:35:33,567 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-57r7b89s', purging\n",
      "2023-02-13 00:35:33,568 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-or0b1941', purging\n",
      "2023-02-13 00:35:33,568 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-y5b_2hhv', purging\n",
      "2023-02-13 00:35:33,568 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-1pdisxj7', purging\n",
      "2023-02-13 00:35:33,569 - distributed.diskutils - INFO - Found stale lock file and directory '/var/folders/w2/91_v34nx0xs2npnl3zsl9tmm0000gn/T/dask-worker-space/worker-br0vpm9n', purging\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       unique_id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id         ds     y  \n",
       "0       CA 2011-01-29  0.01  \n",
       "1       CA 2011-01-30  0.01  \n",
       "2       CA 2011-01-31  0.01  \n",
       "3       CA 2011-02-01  0.01  \n",
       "4       CA 2011-02-02  0.01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = transform(training_data[0:100], \n",
    "                format_sales, \n",
    "                schema=\"unique_id:str,item_id:str,dept_id:str,cat_id:str,store_id:str,state_id:str,ds:date,y:float\",\n",
    "                params={\"start\": start},\n",
    "                engine=\"dask\")\n",
    "ddf.compute().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exogenous Regressors\n",
    "\n",
    "The format above is very close to the format `StatsForecast` expects. We basically already have `unique_id`, `ds`, and `y`. But for this scenario, we want to add price in as an exogenous regressor. Models that can handle exogenous regressors will utilize it, while the ones that can't still just ignore it.\n",
    "\n",
    "Below we load the `sell_prices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price\n",
       "0     CA_1  HOBBIES_1_001     11325        9.58\n",
       "1     CA_1  HOBBIES_1_001     11326        9.58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sell_prices = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')\n",
    "sell_prices.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  wm_yr_wk   weekday  wday  month  year    d event_name_1  \\\n",
       "0 2011-01-29     11101  Saturday     1      1  2011  d_1          NaN   \n",
       "1 2011-01-30     11101    Sunday     2      1  2011  d_2          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN          NaN        0        0        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining All Data\n",
    "\n",
    "In order to combine everything together, we just need to use the `transform()` function earlier on the sales data and then join the other tables. We will sample the `training_data` frame just to test all the joins work before we run it on the full data.\n",
    "\n",
    "For joins, Fugue also has `join` functions that work for Pandas, Spark, Dask, and Ray DataFrames. Here, we'll see how to use it. Again, the advantage is that we don't need to write separate code for both small and large scale data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>11336</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2013-10-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11336</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11336</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2013-10-02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11336</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11336</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       unique_id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id         ds     y  wm_yr_wk  sell_price  \n",
       "0       CA 2013-10-01  2.00     11336        8.26  \n",
       "1       CA 2013-10-04  0.01     11336        8.26  \n",
       "2       CA 2013-09-29  0.01     11336        8.26  \n",
       "3       CA 2013-10-02  0.01     11336        8.26  \n",
       "4       CA 2013-09-28  0.01     11336        8.26  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fugue.api as fa \n",
    "\n",
    "sample = training_data.iloc[0:2].copy()\n",
    "long = transform(sample, \n",
    "                format_sales, \n",
    "                schema=\"unique_id:str,item_id:str,dept_id:str,cat_id:str,store_id:str,state_id:str,ds:date,y:float\",\n",
    "                params={\"start\": start},\n",
    "                engine=\"dask\")\n",
    "\n",
    "# rename the column date to ds\n",
    "calendar_tmp = fa.rename(calendar.copy(), {\"date\": \"ds\"})\n",
    "combined = fa.join(long, calendar_tmp[[\"ds\",\"wm_yr_wk\"]], how=\"left_outer\")\n",
    "combined = fa.join(combined, sell_prices, how=\"inner\")\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rename` function is used to rename the columns of a DataFrame. Now, we can use exactly the same code to run everything on Dask by using the Fugue functions under the Fugue `engine_context()`. We don't need to specify the `engine` under `transform()` anymore because Fugue will know to use Dask.\n",
    "\n",
    "This cell may have a lot of logs about garbage collection warnings when being run on a local machine. This is we will have a number of Dask tasks compared to our resources. When running on a cluster with more compute, this will be less of a problem. It may also take a while to finish (somewhere like 10 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pydata/lib/python3.8/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 49240 instead\n",
      "  warnings.warn(\n",
      "2023-02-13 00:37:14,230 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.51 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:14,616 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.62 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:16,815 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.60 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:16,867 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.81 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:18,302 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.79 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:22,664 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.76 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:26,897 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.87 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:28,342 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.86 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:28,552 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.75 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:32,721 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.87 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:36,919 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.95 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:38,436 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.94 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:38,882 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:39,463 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.88 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:39,482 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.59 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:41,908 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:42,722 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.91 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:43,298 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:43,373 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:46,236 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:46,997 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.95 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:47,524 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:48,617 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.94 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:49,344 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:49,550 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.95 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:49,898 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:51,381 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.80 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:52,731 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:53,158 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:55,357 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:56,999 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:57,259 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:37:58,641 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.94 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:59,561 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.89 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:37:59,616 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:00,391 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:02,821 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.93 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:03,218 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:05,170 - distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:06,689 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:07,001 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.96 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:07,879 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:08,672 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:08,734 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.94 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:10,091 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:11,804 - distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:38:13,305 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:15,198 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.81 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:15,229 - distributed.worker.memory - WARNING - gc.collect() took 1.298s. This is usually a sign that some tasks handle too many Python objects at the same time. Rechunking the work into smaller tasks might help.\n",
      "2023-02-13 00:38:15,288 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.23 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:16,523 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.81 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:16,755 - distributed.worker.memory - WARNING - Worker is at 76% memory usage. Resuming worker. Process memory: 3.08 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:17,332 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.95 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:18,845 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.97 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:20,175 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.99 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:20,737 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.89 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:23,319 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.06 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:24,571 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.81 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:25,219 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.22 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:25,297 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.81 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:25,628 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.20 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:26,567 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.87 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:26,683 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.23 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:27,365 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.20 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:27,463 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.88 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:28,514 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.24 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:28,772 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 3.11 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:30,247 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.15 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:31,128 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.80 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:31,938 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.81 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:33,419 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.98 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:35,409 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.98 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:35,592 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.82 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:36,667 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:38:38,963 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:39:18,420 - distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "2023-02-13 00:39:18,552 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.54 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:44:11,938 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.80 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:44:41,100 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:44:48,583 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 4.00 GiB\n",
      "2023-02-13 00:45:02,465 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.91 GiB -- Worker memory limit: 4.00 GiB\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "\n",
    "with fa.engine_context(client):\n",
    "    long = transform(training_data, \n",
    "                    format_sales, \n",
    "                    schema=\"unique_id:str,item_id:str,dept_id:str,cat_id:str,store_id:str,state_id:str,ds:date,y:float\",\n",
    "                    params={\"start\": start})\n",
    "\n",
    "    # rename the column date to ds\n",
    "    calendar_tmp = fa.rename(calendar.copy(), {\"date\": \"ds\"})\n",
    "    combined = fa.join(long, calendar_tmp[[\"ds\",\"wm_yr_wk\"]], how=\"left_outer\")\n",
    "    combined = fa.join(combined, sell_prices, how=\"inner\")\n",
    "    fa.save(combined, f\"{WORKING_DIR}/combined.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Regression with Exogenous Regressors\n",
    "\n",
    "This is an example of how to run a regression using the exogenous regressors. The important part is that the exogenous regressions need to be available for the forecast horizon.\n",
    "\n",
    "We will just do this on Pandas to quickly demo, but it can be scale on the distributed backends as well using the `FugueBackend()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pydata/lib/python3.8/site-packages/statsforecast/core.py:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast import StatsForecast\n",
    "\n",
    "sample = training_data.iloc[0:1].copy()\n",
    "long = transform(sample, \n",
    "                format_sales, \n",
    "                schema=\"unique_id:str,item_id:str,dept_id:str,cat_id:str,store_id:str,state_id:str,ds:date,y:float\",\n",
    "                params={\"start\": start})\n",
    "calendar_tmp = fa.rename(calendar.copy(), {\"date\": \"ds\"})\n",
    "combined_exo = fa.join(long, calendar_tmp[[\"ds\",\"wm_yr_wk\"]], how=\"left_outer\")\n",
    "combined_exo = fa.join(combined_exo, sell_prices, how=\"inner\")\n",
    "combined_exo = combined_exo[['unique_id', 'ds', 'y', 'sell_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>1.117753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>1.117753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>1.117753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>1.120463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>1.120463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1.117753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_001_CA_1_evaluation</th>\n",
       "      <td>2016-05-29</td>\n",
       "      <td>1.118650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ds  AutoARIMA\n",
       "unique_id                                          \n",
       "HOBBIES_1_001_CA_1_evaluation 2016-05-23   1.117753\n",
       "HOBBIES_1_001_CA_1_evaluation 2016-05-24   1.117753\n",
       "HOBBIES_1_001_CA_1_evaluation 2016-05-25   1.117753\n",
       "HOBBIES_1_001_CA_1_evaluation 2016-05-26   1.120463\n",
       "HOBBIES_1_001_CA_1_evaluation 2016-05-27   1.120463\n",
       "HOBBIES_1_001_CA_1_evaluation 2016-05-28   1.117753\n",
       "HOBBIES_1_001_CA_1_evaluation 2016-05-29   1.118650"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StatsForecast(\n",
    "    df=combined_exo,\n",
    "    models=[AutoARIMA(season_length=7)], \n",
    "    freq='D', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# We can forecast for one timeseries. \n",
    "# We need the future values of exogenous regressors.\n",
    "sample = pd.DataFrame({\n",
    "    'unique_id': ['HOBBIES_1_002_CA_1_evaluation']*7,\n",
    "    'ds': pd.date_range(start='2016-05-22', end='2016-05-28').tolist(),\n",
    "    'sell_price': [3.97] * 7\n",
    "})\n",
    "# Pass a forecast to the forecast\n",
    "model.forecast(7, X_df=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next two sections, we'll explore two different topics. The first one is Hierarchical Forecasting using Nixtla's [hierarchicalforecast](https://github.com/Nixtla/hierarchicalforecast) library. In the second one, we look at how to scale this over a cluster using Coiled to get managed Dask clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pydata')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a90540e516f4536bf5dbe9567094367903ef88dff4cbaca37f797bacdfcf4db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
